# Классификация цифр (MNIST) на Java
 

Цель программы: взять маленькую картинку(MNIST состоит из маленьких картинок) с рукописной цифрой от 0 до 9 и попытаться угадать, какая цифра на изображении.

Вся основная логика находится в классе `App` в методе `main`. В начале задаются простые параметры: 

`batchSize` — сколько картинок подаём в сеть за один раз, 

`numEpochs` — сколько раз мы проходим весь обучающий набор, 

`numClasses` — количество классов (цифры 0–9, значит 10 классов), 

размер изображения 28x28 и один канал, потому что картинки чёрно‑белые. 

После этого создаются два итератора для датасета MNIST: `trainIterator` для обучения и `testIterator` для тестирования. При первом запуске датасет сам скачивается

### Конфигурация свёрточной нейронной сети

в переменной `config` задаётся два свёрточных слоя с активацией ReLU, между ними слои подвыборки (max pooling), затем один полносвязный слой и выходной слой с softmax на 10 классов. 
Также явно указывается тип входа — изображение 28x28 с одним каналом. 

### Обучение

Когда конфигурация готова, создаётся объект `MultiLayerNetwork model`, вызывается `init()`, и к модели подключается слушатель `ScoreIterationListener`, который периодически печатает значение функции ошибки во время обучения. 
Затем начинается обучение: в цикле по количеству эпох вызывается `model.fit(trainIterator)`, то есть сеть проходит по всем батчам(пачки примеров из датасета) обучающих данных и обновляет свои веса. 
После каждой эпохи итератор сбрасывается методом `reset()`. 
В работе количество эпох выбрано равным единице, чтобы обучение занимало немного времени и программа выполнялась быстро.

----

После обучения модель нужно оценить на тестовых данных. Для этого используется класс `Evaluation`. 
Сначала печатается сообщение о начале оценки, затем вызывается `model.evaluate(testIterator)`, и результат сохраняется в объект `eval`.
Метод `eval.stats()` выводит в консоль отчёт: точность, матрицу ошибок и другие стандартные метрики качества модели. 
Так можно увидеть, насколько хорошо сеть научилась распознавать цифры, которых она не видела при обучении.

В конце программы добавлен небольшой пример работы модели на одной картинке. 
Тестовый итератор сбрасывается, берётся следующий батч и из него извлекаются признаки (пиксели) и метки (настоящие цифры). 
Вызов `model.output(features)` даёт предсказания для этого батча. С помощью `argMax(1)` из меток и предсказаний берётся индекс максимального значения — это номер цифры. В консоль выводятся настоящая цифра и цифра, которую выдала модель, чтобы можно было наглядно увидеть пример предсказания. В конце печатается сообщение о завершении работы программы.


-----
Тесты находятся в пакете `org.example` в отдельном классе. 
В тестах создаётся та же самая модель с такой же конфигурацией слоёв, как и в `App`, чтобы проверять именно тот вариант сети, который используется в основной программе. 
Првый тест берёт небольшой батч данных из обучающего MNIST, делает один шаг обучения `model.fit(...)`, затем считает предсказания на маленьком тестовом наборе и с помощью класса `Evaluation` вычисляет точность. 
В тесте проверяется, что точность больше нуля, то есть модель действительно что‑то предсказывает и корректно работает с данными.
Второй тест берёт одну картинку из тестового набора, слегка обучает модель на маленьком батче, прогоняет эту картинку через сеть и проверяет, что реальная цифра и предсказанная цифра лежат в диапазоне от 0 до 9. 
Эти тесты по сути просто проверяют, что нейросеть работоспособна и предсказанная цифра хотя бы в диапазоне.


----

Запуск тестов: `./gradlew test`. 
Запуск программы `./gradlew run`. 
При первом запуске Gradlом скачиваются все нужные библиотеки и датасет MNIST,
после запуска в консоли появляется сообщения об обучении, отчёт о точности на тестовой выборке и пример предсказания для одной картинки.
