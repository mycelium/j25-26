# Лабораторная работа 7: Параллельное умножение матриц

## Описание задачи
Реализация параллельного алгоритма умножения матриц с использованием многопоточности в Java.

## Реализованные методы
- `multiply(double[][] A, double[][] B)` - однопоточная реализация
- `multiplyParallel(double[][] A, double[][] B)` - многопоточная реализация с транспонированием матрицы

## Особенности реализации
- **Транспонирование матрицы**: Вторая матрица транспонируется для улучшения локальности данных
- **Кэширование ссылок**: Используются ссылки на строки матриц для уменьшения обращений к массивам
- **Распределение по строкам**: Каждый поток обрабатывает блок строк результирующей матрицы

## Результаты тестирования

### Конфигурация системы
- Процессор: 4 ядра
- Платформа: Java

### Производительность

| Размер матрицы | Однопоточное (мс) | Многопоточное (мс) | Ускорение |
|----------------|-------------------|-------------------|-----------|
| 200×200        | 30,24             | 19,15             | 1,58×     |
| 500×500        | 1350,77           | 94,56             | 14,28×    |
| 1000×1000      | 1839000,90        | 663,81            | 2770,36×  |
| 1500×1500      | 100322,53         | 3044,17           | 32,96×    |

### Поиск оптимального количества потоков
Для матрицы 1000×1000:

| Количество потоков | Время (мс) |
|---------------------|------------|
| 1                   | 2161,22    |
| 2                   | 893,72     |
| 3                   | 615,46     |
| 4                   | 625,11     |
| 5                   | 611,50     |
| 6                   | 621,22     |
| 7                   | **566,70** |
| 8                   | 590,01     |

**Оптимальное количество потоков: 7**

## Анализ результатов

### Зависимость ускорения от размера матрицы
1. **Малые матрицы (200×200)**: Ускорение 1,58× - незначительное, так как накладные расходы на создание потоков сопоставимы с вычислительной нагрузкой
2. **Средние матрицы (500×500)**: Ускорение 14,28× - хорошая эффективность параллелизации
3. **Большие матрицы (1000×1000)**: Максимальное ускорение благодаря оптимальному соотношению вычислений и накладных расходов

### Оптимальное количество потоков
- **Теоретически ожидалось**: 4 потока (по количеству ядер)
- **Фактически оптимально**: 7 потоков
- **Объяснение**: 
  - Hyper-Threading позволяет эффективно использовать больше логических потоков
  - Современные процессоры могут оптимально распределять нагрузку между логическими ядрами
  - Транспонирование матрицы уменьшает contention за доступ к памяти

## Выводы
1. **Эффективность параллелизации** сильно зависит от размера матриц
2. **Транспонирование матрицы** является ключевой оптимизацией для многопоточного выполнения
3. **Оптимальное количество потоков** может превышать количество физических ядер
4. **Для вычислительно сложных задач** многопоточность дает значительное ускорение
