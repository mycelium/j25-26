# HSAI 25-26 Java course - 1
## 7. Java: Parallel matrix multiplication
### Задание:
- Реализовать функцию `public static double[][] multiplyParallel(double[][] firstMatrix, double[][] secondMatrix);`
- Реализация должна использовать многопоточность
- Вывести время выполнения для матриц большой размерности
- Сравнить время с однопоточной реализацией из лабораторной 1
- Подобрать оптимальное количество потоков под вашу платформу, описать подход к подбору в README
   
### Подход к подбору оптимального числа потоков под любую платформу
Для удобного подбора оптимального количества потоков под платформу в классе была реализована функция `private static int getBestThreadAmount(int matrixSize, boolean isLogging)`, которая вычисляет лучшее число потоков для матрицы заданного пользователем размера. Функция также принимает необязательный параметр `boolean isLogging`, которая отвечает за то, чтобы пользователю выводилась дополнительная информация о ходе вычисления лучшего числа потоков.

Стоит отметить, что функция предназначена только для использования внутри класса.

### Сравнение производительностей с умножением матриц из лабораторной работы № 1
Несмотря на то, что в первой работе для больших матриц используется алгоритм блочного умножения матриц (для лучшей cache locality), а в текущей используется более простой подход - умножения матрицы на транспонированную матрицу (которая незначительно улучшает cache locality (много хуже, чем с помощью блочной матрицы)), многопоточенное решение все равно выигрывает в скорости у однопоточного умножения.

| Размер матрицы | Лабораторная работа № 1 | Лабораторная работа № 7 | Улучшение в _ раз |
|----------------|-------------------------|-------------------------|-------------------|
| 100x100        | ~0.54ms                 | ~1.3ms                  | ~0.41             |
| 500x500        | ~41.00ms                | ~23.72ms                | ~1.73             |
| 1000x1000      | ~286.10ms               | ~220.20ms               | ~1.30             |
| 1500x1500      | ~5544.61ms              | ~590.51ms               | ~9.39             |

Как видно из сравнительной таблицы, многопоточное решение не самое эффективное для маленьких матриц, так как бОльшую часть времени мы тратим на обработку потоков, чем на вычисление результата. 

Для более больших матриц, которые в первой работе вычисляются с помощью умножения на транспонированную матрицу, решение лабораторной работы № 7 показывают достаточно высокий результат улучшения.

При переходе на умножение матриц по блокам сначала эффективность алгоритма лабораторной работы № 7 незначительно падает, но крайне быстро возрастает: при умножении матриц 1000x1000 улучшение только в 1.3 раза, а для 1500x1500 - уже в 9.4 раза!

Таким образом, несмотря на использование более простого алгоритма умножения матриц, параллельное умножение матриц показывает результат намного лучше, чем любая реализация умножения больших матриц (более 100х100).