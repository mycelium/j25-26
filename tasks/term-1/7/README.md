# Параллельное умножение матриц

## Анализ платформы
- **Логические процессоры**: 20
- **Физические ядра**: 14

## Результаты тестирования

| Размер матрицы | Последовательная | Параллельная | Потоки | Ускорение | Результат |
|----------------|------------------|--------------|--------|-----------|-----------|
| 100×100        | 3 ms             | 18 ms        | 5      | 0.17x     | Последовательная на 83.3% быстрее |
| 200×200        | 3 ms             | 2 ms         | 5      | 1.50x     | Параллельная на 50.0% быстрее |
| 500×500        | 50 ms            | 13 ms        | 14     | 3.85x     | Параллельная на 284.6% быстрее |
| 1000×1000      | 436 ms           | 65 ms        | 20     | 6.71x     | Параллельная на 570.8% быстрее |
| 2000×2000      | 4679 ms          | 449 ms       | 20     | 10.42x    | Параллельная на 942.1% быстрее |

## Определение оптимального количества потоков

### 1. Матрица 100×100 → 5 потоков
- Маленький объем вычислений
- Накладные расходы на создание потоков превышают выгоду
- Используется ~35% физических ядер для минимизации контекстных переключений

**Результат**: Speedup 0.17x - подтверждает, что для маленьких матриц многопоточность неэффективна, поэтому для матриц меньше 100×100 → 1 поток.

### 2. Матрицы 200×200 → 5 потоков  
- Умеренный объем вычислений
- Баланс между параллелизацией и накладными расходами

**Результат**: Speedup 1.50x - многопоточность становится слегка эффективнее

### 3. Матрицы 500×500 → 14 потоков
- Значительный объем вычислений
- Использование 100% физических ядер

**Результат**: Speedup 3.85x - многопоточность эффективнее

### 4. Матрицы 1000×1000+ → 20 потоков
- Большой объем вычислений
- Использование 100% логических процессоров
- Максимальное распараллеливание

**Результат**: Speedup 6.71x-10.42x - на больших матрицах многопоточность значительно эффективнее

Выбор оптимального количества потоков реализован в методе getOptimalThreadCount. Также обе версии алгоритма используют его оптимизированную версию с использованием транспонирования второй матрицы.
