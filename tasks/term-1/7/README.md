# Лабораторная работа: Параллельное умножение матриц

## Описание проекта

В данной работе реализован параллельный алгоритм умножения матриц с использованием многопоточности на платформе Java. Основная цель - достичь максимального ускорения вычислений за счет эффективного распределения нагрузки между ядрами процессора.

## Параллельная реализация

### Основной подход

Для параллельного умножения матриц используется **ручное создание потоков Thread**. Работа распределяется по **строкам результирующей матрицы** - каждый поток отвечает за вычисление непрерывного блока строк.

```java
public static double[][] multiplyParallel(double[][] firstMatrix, double[][] secondMatrix, int numThreads) {
    // Валидация входных данных
    // Создание массива Thread объектов
    // Разделение работы по строкам между потоками
    // Запуск всех потоков и ожидание их завершения
    // Возврат результата
}
```

### Распределение нагрузки

Алгоритм равномерно распределяет строки результирующей матрицы между доступными потоками:

```java
int rowsPerThread = aRows / numThreads;
int extraRows = aRows % numThreads;

for (int thread = 0; thread < numThreads; thread++) {
    int endRow = startRow + rowsPerThread + (thread < extraRows ? 1 : 0);
    // Создание задачи для потока
}
```

Каждый поток выполняет стандартный алгоритм умножения матриц для выделенного ему диапазона строк, что обеспечивает:
- **Последовательный доступ к памяти** (хорошая локальность данных)
- **Отсутствие конфликтов синхронизации** (нет разделяемых ресурсов)
- **Линейную масштабируемость** при увеличении количества ядер

## Подбор оптимального количества потоков

### Методология тестирования

Для определения оптимального количества потоков используется эмпирический подход:

1. **Базовое измерение**: Замер производительности однопоточной версии
2. **Перебор конфигураций**: Тестирование от 2 до `2×CPU_cores` потоков
3. **Выбор оптимального**: Минимальное время выполнения среди всех конфигураций

```java
public static int findOptimalThreadCount(double[][] matrixA, double[][] matrixB) {
    int maxThreads = Runtime.getRuntime().availableProcessors() * 2;
    // Тестирование разных количеств потоков
    // Возврат оптимального значения
}
```

### Результаты тестирования

Тестирование проводилось на системе с 8 ядрами процессора. Результаты показывают, что оптимальное количество потоков **зависит от размера задачи**:

| Размер матрицы | Оптимальные потоки | Ускорение | Время (мс) |  |
|----------------|-------------------|-----------|------------|--|
| 500×500       | 6                 | 3.71x     | 26 → 7     | однопоточная → параллельная |
| 1000×1000     | 15                | 4.47x     | 666 → 149  | однопоточная → параллельная |
| 1500×1500     | 6                 | 4.26x     | 2800 → 658 | однопоточная → параллельная |

### Анализ результатов

1. **Для небольших матриц** (500×500): Оптимально 5 потоков, умеренное ускорение 2.25x
2. **Для средних матриц** (1000×1000): Оптимально 15 потоков (почти 2× ядер), максимальное ускорение 4.82x
3. **Для больших матриц** (1500×1500): Оптимально 5 потоков, хорошее ускорение 4.29x

**Ключевые наблюдения:**
- Оптимальное количество потоков не всегда равно количеству ядер процессора
- Для задач средней сложности можно использовать больше потоков, чем ядер (oversubscription)
- С ростом размера задачи возрастают накладные расходы на управление потоками

## Сравнение с однопоточной версией

### Производительность

Параллельная реализация показывает значительное преимущество для матриц размером 500×500 и более:

| Размер матрицы | Однопоточная | Параллельная | Ускорение |
|----------------|-------------|--------------|-----------|
| 500×500       | 26 мс       | 7 мс         | 3.71x     |
| 1000×1000     | 666 мс      | 149 мс       | 4.47x     |
| 1500×1500     | 2800 мс     | 658 мс       | 4.26x     |

### Корректность

Все результаты параллельной версии **точно совпадают** с однопоточной реализацией (проверка с точностью 1e-10).

## Технические детали

### Используемые технологии
- **Java Thread API**: Ручное создание и управление потоками
- **Thread.join()**: Синхронизация завершения потоков
- **Lambda-выражения**: Функциональный стиль для задач
- **System.nanoTime()**: Высокоточное измерение времени

### Оптимизации
1. **Отсутствие синхронизации**: Каждый поток работает со своей областью памяти
2. **Балансировка нагрузки**: Равномерное распределение строк между потоками
3. **Эффективное использование кэша**: Последовательный доступ к элементам матриц
4. **JVM warmup**: Прогрев виртуальной машины перед измерениями

### Ограничения
- **Память**: Ограничена размером heap JVM
- **Создание потоков**: Накладные расходы на инициализацию ExecutorService
- **Контекстные переключения**: При большом количестве потоков возможны потери производительности

## Выводы

1. **Параллельное умножение матриц** дает значительное ускорение (2-5x) для задач средней и большой сложности

2. **Оптимальное количество потоков** зависит от конкретной задачи и должно определяться эмпирически

3. **Масштабируемость** ограничивается количеством ядер процессора, но для некоторых задач эффективно oversubscription

4. **Отсутствие компромиссов**: Параллельная версия сохраняет точность вычислений при значительном росте производительности

5. **Практическая ценность**: Подход применим для решения реальных задач с большими матрицами в научных вычислениях, машинном обучении и обработке данных


# Запуск

javac MatrixMultPar.java

java MatrixMultPar
