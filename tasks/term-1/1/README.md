## Отчет по работе 1. Java: Matrix multiplication
### Введение
---
Вычисление произведения матриц является фундаментальной математической задачей. Она актуальна в программировании благодаря различным способам представления матриц в программе и необходимости проверки соответствия количества столбцов первой матрицы и строк второй матрицы. И в частности из-за алгоритма, который используется для вычисления результата. Поскольку матрицы могут обладать большим количеством элементов, необходимо найти оптимальный способ, который позволит рационально распорядиться большим объемом данных и получить корректный результат без значительных затрат времени.

### Термины 
---
**Кеш-линия** - минимальный блок данных, передаваемый от основной памяти к кеш-памяти;

**Кеш-промах** - ситуация, когда процессор пытается обратиться к данным и не находит их в кеш-памяти;

### Цель
---
* Реализация функции `public static double[][] multiply(double[][], double[][]);`, выполняющей умножение двух матриц.
* Вывод времени выполнения для матриц большой размерности.
* Оптимизация времени выполнения и описание примененных подходов.

### Описание начального алгоритма
---
Изначальное решение поставленной задачи реализовано при помощи трех циклов. Два внешних цикла i и j проходят по индексам строк и столбцов конечной матрицы, в то время как внутренний цикл k - по индексам столбцов матрицы правого операнда. Сложность алгоритма O(n³).

```java
// res - конечная матрица
// n   - количество строк конечной матрицы
// m   - количество столбцов конечной матрицы
// p   - количество столбцов первой матрицы
for (int i = 0; i < n; i++)  
    for (int j = 0; j < m; j++)  
        for(int k = 0; k < p; k++)  
            res[i][j] += firstMatrix[i][k] * secondMatrix[k][j];
```

Ключевая проблема заключается в том, что внутренний цикл обращается к элементам `secondMatrix[k][j]` при инкрементации k, что приводит к обращению по столбцам. Каждое обращение требует загрузки новой кеш-линии, так как элементы находятся в разных строках матрицы. Это приводит к большому количеству кеш-промахов.
### Описание способов оптимизации
Способами оптимизации были выбраны **Изменение порядка циклов**, **Транспонирование второй матрицы** и **Разбиение матриц на блоки**.

**Изменение порядка циклов**
* **Описание:** Изменен порядок циклов. Теперь вторым циклом идет цикл k, а третьим цикл j.
* **Обоснование:** Благодаря тому, что в данной реализации k является фиксированным для внутреннего цикла, с каждой итерацией вместо обращения к разным строкам матрицы `secondMatrix` происходит последовательное обращение к элементам массива, которые блоками загружаются в кеш-линию. Это позволяет значительно уменьшить количество кеш-промахов.

```java
for (int i = 0; i < n; i++)  
    for (int k = 0; k < p; k++) {  
        double firstVal = firstMatrix[i][k];  
        for (int j = 0; j < m; j++)  
            res[i][j] += firstVal * secondMatrix[k][j];  
    }
```

**Транспонирование левой матрицы**
*  **Описание:** Перед выполнением вычислений транспонируем вторую матрицу.
*  **Обоснование:** Из-за транспонирования матрицы обращение к двойному массиву заменяется с `[k][j]` на `[j][k]`. Благодаря тому, что внутренний цикл итерируется по j, это уменьшает количество кеш-промахов.

```java
for (int i = 0; i < n; i++)  
    for (int j = 0; j < m; j++) {  
        double sum = 0;  
        for (int k = 0; k < tmpM.length; k++)  
            sum += firstMatrix[i][k] * tmpM[j][k];  
        res[i][j] += sum;  
    }
```

**Разбиение на блоки**
* **Описание:** Разбиваем матрицы на блоки и вычисляем результат по данным блокам.
* **Обоснование:** Благодаря тому, что вычисление происходит с каждым блоком последовательно и раздельно, блоки загружаются в кеш полностью, и количество кеш-промахов сокращается.

```java
// blockSize - размерность блока
for (int i0 = 0; i0 < n; i0 += blockSize)  
    for (int j0 = 0; j0 < m; j0 += blockSize)  
        for (int k0 = 0; k0 < p; k0 += blockSize) {  
  
            int iBlockSize = Math.min(i0 + blockSize, n);  
            int jBlockSize = Math.min(j0 + blockSize, m);  
            int kBlockSize = Math.min(k0 + blockSize, p);  
  
            for (int i = i0; i < iBlockSize; i++)  
                for (int j = j0; j < jBlockSize; j++)  
                    for (int k = k0; k < kBlockSize; k++)  
                        res[i][j] += firstMatrix[i][k] * secondMatrix[k][j];  
        }  
return res;
```

**Комбинация Изменения порядка циклов и Разбиение на блоки**
* **Описание:** Разбиваем на блоки и при этом изменяем порядок циклов во внутренних трех циклах, которые проходятся по отдельным блокам.
* **Обоснование:** Комбинация позволяет одновременно использовать разбиение на блоки, позволяя блокам помещаться в кеш-память. Изменение порядка циклов внутри блока оптимизирует доступ к отдельным кеш-линиям, обеспечивая последовательное чтение данных и максимальное использование каждой загруженной кеш-линии.

```java
for (int i0 = 0; i0 < n; i0 += blockSize)  
    for (int k0 = 0; k0 < p; k0 += blockSize)  
        for (int j0 = 0; j0 < m; j0 += blockSize) {  
  
            int iBlockSize = Math.min(i0 + blockSize, n);  
            int jBlockSize = Math.min(j0 + blockSize, m);  
            int kBlockSize = Math.min(k0 + blockSize, p);  
  
            for (int i = i0; i < iBlockSize; i++)  
                for (int k = k0; k < kBlockSize; k++) {  
                    double firstVal = firstMatrix[i][k];  
                        for (int j = j0; j < jBlockSize; j++)  
                            res[i][j] += firstVal * secondMatrix[k][j];  
                }  
        }
```

### Результаты 
---
![Таблица со сравнением способов оптимизации](./1/Table.png)

###  Вывод
---
Наилучшими способами оптимизации являются Изменение порядка циклов и комбинация данного метода с разбиением на блоки. При этом комбинированный метод начинает опережать простой вариант с изменением порядка циклов при увеличении размерности матриц. Также можно заметить, что эффективность Разбиения на блоки значительно возрастает с ростом количества элементов. Оба этих результата объясняются тем, что загрузка данных блоками в кеш становится более эффективной при увеличении общего объема обрабатываемых данных, когда матрицы перестают помещаться в кеш-память целиком.

Транспонирование демонстрирует незначительный коэффициент ускорения для небольших матриц, однако для больших размеров его эффективность существенно возрастает. Процесс транспонирования, который является значительным фактором снижения производительности данного метода для маленьких матриц, оказывает меньшее влияние на общее время вычислений для больших матриц.
