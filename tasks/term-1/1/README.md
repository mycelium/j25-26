# Лабораторная работа 1: Оптимизация умножения матриц

## Описание проекта

В данной работе реализованы и сравниваются два алгоритма умножения матриц: классический базовый алгоритм и оптимизированная версия с использованием транспонирования для улучшения локальности данных.

## Теоретическое обоснование оптимизации

Основная проблема классического алгоритма умножения матриц заключается в способе доступа к данным: в тройном вложенном цикле при обращении к элементам второй матрицы `B[k][j]` происходит доступ по столбцам, что означает переход между разными строками матрицы при каждом изменении индекса k. Такой случайный доступ к памяти приводит к частым кэш-промахам, когда процессору приходится ожидать данные из медленной оперативной памяти вместо быстрого кэша.

Суть оптимизации заключается в транспонировании второй матрицы перед умножением, т. к. после транспонирования `Bᵀ[j][k] = B[k][j]`, мы получаем возможность обращаться к элементам обеих матриц последовательно: `A[i][k]` и `Bᵀ[j][k]`. Такой последовательный доступ позволяет эффективно использовать кэш процессора, поскольку данные загружаются блоками и многократно переиспользуются перед вытеснением из кэша.

## Полученные результаты 

Можно заметить зависимость эффективности оптимизации от размера матриц, например, в результате одного из запусков программы были получены следующие результаты:

| Размер матрицы | Базовый алгоритм | Оптимизированный | Ускорение |
|----------------|------------------|------------------|-----------|
| 100×100        | 4 мс             | 4 мс             | 1,00x     |
| 500×500        | 118 мс           | 56 мс            | 2,11x     |
| 1000×1000      | 1347 мс          | 463 мс           | 2,91x     |
| 2000×2000      | 64789 мс         | 5144 мс          | 12,60x    |

## Анализ результатов

Для маленьких матриц размером 100×100 оба алгоритма показывают одинаковое время выполнения (а иногда базовый может оказаться быстрее), т. к. матрицы такого размера полностью помещаются в кэш процессора даже при неоптимальном доступе,а дополнительные затраты на операцию транспонирования становятся значительными относительно общего времени вычислений.

Ситуация кардинально меняется для больших матриц: уже для размера 500×500 оптимизированный алгоритм показывает ускорение более чем в 2 раза, а для умножения матриц размером 2000×2000 ускорение происходит в 12 раз. Такой рост эффективности объясняется тем, что большие матрицы не помещаются в кэш процессора и требуют постоянного обращения к оперативной памяти - в этом случае стоимость кэш-промахов становится доминирующим фактором, и выигрыш от последовательного доступа к данным значительно превышает затраты на предварительное транспонирование матрицы.

## Выводы

На основе полученных результатов можно сделать вывод о существовании порога эффективности оптимизации, который находится в районе 200×200 элементов. Для матриц меньшего размера базовый алгоритм будет эффективнее, в то время как для больших матриц оптимизированная версия с транспонированием значительно сократит время выполнения операции умножения матриц. Критическим фактором, определяющим эффективность оптимизации, является соотношение между размером обрабатываемых данных и объемом кэш-памяти процессора: когда рабочий набор данных значительно превышает размер кэша, оптимизация доступа к памяти становится важнее, чем минимизация количества операций. Это особенно заметно на примере матриц 2000×2000, где каждая матрица занимает около 32 МБ, что может превышать типичный размер кэша современных процессоров, в таких условиях даже относительно дорогостоящая операция транспонирования окупается многократно за счет радикального сокращения времени доступа к памяти в основном цикле умножения.

