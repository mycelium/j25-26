# Оптимизации умножения матриц
Реализованное умножение двух матриц, содержит такие оптимизации как оптимизация кэш-лояльности и параллелизация.
## Оптимизация кэш-лояльности
При каждом запросе данных из оперативной памяти процессор заносит полученные байты в собственный кэш, так как если сейчас понадобились данные, то вероятно, что эти данные скоро понадобятся снова (Временная локальность). Также при обращении к определённому элементу памяти в кэш заносятся ещё и соседнии элементы (Пространственная локальность). 
При использовании стандартного способа умножения матриц пространственная локальность не соблюдается, а конкретно при доступе к `secondMatrix[c][x]`, потому что его соседними элементами в памяти являются `secondMatrix[c][x-1]` и `secondMatrix[c][x+1]` и т.д., но не `secondMatrix[c+1][x]`. 
```
for (int y = 0; y < firstRows; y++){
    for (int x = 0; x < secondCols; x++){
        double s = 0;
        for (int c = 0; c < firstCols; c++){
            s += firstMatrix[y][c] * secondMatrix[c][x];
        }
        resMatrix[y][x] = s;
    }
}
```
Для исправления этого можно транспонировать вторую матрицу, что сделает доступ к `secondMatrixTrans[x][c]` последовательным, тем самым улучшив локальность.
```
for (int y = 0; y < firstRows; y++) {
    for (int x = 0; x < secondCols; x++) {
        double sum = 0.0;
        for (int c = 0; c < firstCols; c++) {
            sum += firstMatrix[y][c] * secondMatrixTrans[x][c];
        }
        result[i][j] = sum;
    }
}
```
## Параллелизация
Так как при перемножении матриц программа не изменяет их элементы и не использует общие переменные при расчётах разных элементов итоговой матрицы (то есть нет гонки за данными), то можно использовать параллелизацию процессов. В данном случае используется параллелизация по строкам результирующей матрицы, так как при параллелизации по столбцам каждый поток будет записывать данные сразу в несколько строк (resMatrix[0][0], resMatrix[1][0], resMatrix[2][0] и т.д.), что замедляет работу. Также нельзя использовать параллелизацию во внутреннем цикле, который является редукцией (накоплением), потому что в нём используется общая для всех итераций переменная `double s`, значение которой увеличивается при каждой итерации.
Итоговый код с учётом оптимизации кэш-лояльности и параллелизации внешнего цикла (по строкам):
```
public static double[][] multiplyTransposeParallel(double[][] firstMatrix, double[][] secondMatrix) {
		int firstRows = firstMatrix.length;
		int firstCols = firstMatrix[0].length;
		int secondRows = secondMatrix.length;
		int secondCols = secondMatrix[0].length;

		if (firstCols != secondRows) {
			throw new IllegalArgumentException("Данные матрицы нельзя умножить! Число столбцов первой матрицы должно быть равно числу столбцов второй матрицы.");
		}

		double[][] secondMatrixTrans = transpose(secondMatrix);
		double[][] resMatrix = new double[firstRows][secondCols];
		
		IntStream.range(0, firstRows)
		.parallel()
		.forEach(y -> {
			for (int x = 0; x < secondCols; x++) {
				double s = 0.0;
				for (int c = 0; c < firstCols; c++) {
					s += firstMatrix[y][c] * secondMatrixTrans[x][c];
				}
				resMatrix[y][x] = s;
			}
		});
		return resMatrix;
	}
```
# Время выполнения
При перемножении двух матриц размерами 1000x1600 и 1600x1800 были получены следующие результаты:
```
Среднее время для стандартного умножения (10 тестов): 25538 мс
Среднее время для оптимизированного умножения (10 тестов): 238 мс
```
Оптимизированный вариант работает в среднем в 107 раз быстрее, чем обычный вариант данного метода.