# Отчет об исследовании производительности алгоритмов умножения матриц

## Введение

### Проблематика
Умножение матриц является фундаментальной операцией в линейной алгебре с широким спектром применений в научных вычислениях, машинном обучении, компьютерной графике и других областях. Классический алгоритм умножения матриц имеет вычислительную сложность O(n³), что делает задачу оптимизации критически важной для работы с матрицами больших размеров.

### Цель исследования
Сравнительный анализ производительности различных оптимизированных алгоритмов умножения матриц и выявление наиболее эффективных подходов с точки зрения компьютерной архитектуры и математической оптимизации.

## Математические основы умножения матриц

### Стандартное матричное умножение
Для матриц A размером m×n и B размером n×p результатом умножения является матрица C размером m×p, где каждый элемент вычисляется по формуле:
C[i][j] = Σ(k=0 to n-1) A[i][k] * B[k][j]

Это соответствует тройному вложенному циклу с порядком i-j-k.

## Детальный анализ алгоритмов

### 1. Классический алгоритм (Classic)

**Математическая формализация:**
```python
for i in range(m):
    for j in range(p):
        sum = 0
        for k in range(n):
            sum += A[i][k] * B[k][j]
        C[i][j] = sum
```

**Компьютерно-архитектурный анализ:**
- **Проблема кэш-памяти**: При доступе к B[k][j] для фиксированного j и изменяющегося k происходит скачкообразный доступ к памяти (strided access)
- **Локализация данных**: Низкая пространственная локализация для матрицы B
- **Кэш-промахи**: Высокая вероятность кэш-промахов при больших размерах матриц
- **Вычислительная сложность**: O(n³) без учета оптимизаций доступа к памяти

### 2. Оптимизированный алгоритм (Optimized)

**Математическая формализация:**
```python
for i in range(m):
    for k in range(n):
        temp = A[i][k]
        for j in range(p):
            C[i][j] += temp * B[k][j]
```

**Компьютерно-архитектурный анализ:**
- **Улучшенная локализация**: Последовательный доступ к элементам B[k][j] для фиксированного k
- **Кэширование**: Элемент A[i][k] кэшируется в регистре процессора
- **Векторизация**: Более предсказуемый доступ к памяти позволяет компилятору применять векторные инструкции
- **Теоретическое ускорение**: До 5-10 раз за счет лучшего использования кэша L1/L2

### 3. Блочный алгоритм (Blocked)

**Математическая формализация:**
```python
for i0 in range(0, m, blockSize):
    for j0 in range(0, p, blockSize):
        for k0 in range(0, n, blockSize):
            for i in range(i0, min(i0+blockSize, m)):
                for k in range(k0, min(k0+blockSize, n)):
                    temp = A[i][k]
                    for j in range(j0, min(j0+blockSize, p)):
                        C[i][j] += temp * B[k][j]
```

**Компьютерно-архитектурный анализ:**
- **Иерархия памяти**: Работа с блоками, которые полностью помещаются в кэш L1/L2/L3
- **Принцип локальности**: Временная и пространственная локальность данных максимизируется
- **Оптимальный размер блока**: Определяется размером кэша процессора (обычно 32-128 элементов)
- **Теоретическое ускорение**: До 3-8 раз для оптимально подобранного размера блока

### 4. Алгоритм с транспонированием (With Transpose)

**Математическая формализация:**
```python
B_transposed = transpose(B)   # Функция transpose должна быть определена

for i in range(m):
    for j in range(p):
        sum_val = 0
        for k in range(n):
            sum_val += A[i][k] * B_transposed[j][k]
        C[i][j] = sum_val
```

**Компьютерно-архитектурный анализ:**
- **Последовательный доступ**: Обеспечивается последовательный доступ к обоим операндам
- **Накладные расходы**: Затраты на транспонирование O(n²) компенсируются выигрышем O(n³) в основном вычислении
- **Кэш-дружественность**: Улучшенное предсказание доступа к памяти
- **Теоретическое ускорение**: До 2-4 раз для больших матриц

### 5. Алгоритм с развертыванием цикла (Unrolled)

**Математическая формализация:**
```python
unrollFactor = 4

for i in range(m):
    for k in range(n):
        temp = A[i][k]
        j = 0
        while j < p - unrollFactor:
            C[i][j] += temp * B[k][j]
            C[i][j+1] += temp * B[k][j+1]
            C[i][j+2] += temp * B[k][j+2]
            C[i][j+3] += temp * B[k][j+3]
            j += unrollFactor
        while j < p:
            C[i][j] += temp * B[k][j]
            j += 1
```

**Компьютерно-архитектурный анализ:**
- **Уменьшение overhead**: Снижение количества проверок условий циклов
- **Инструкционный параллелизм**: Возможность параллельного выполнения нескольких операций
- **Регистровая оптимизация**: Улучшенное использование регистров процессора
- **Теоретическое ускорение**: До 1.5-3 раз в зависимости от архитектуры

### 6. Комбинированный алгоритм (Combined)

**Математическая формализация:**
```python
B_transposed = transpose(B)

for i0 in range(0, m, blockSize):
    for j0 in range(0, p, blockSize):
        for k0 in range(0, n, blockSize):
            for i in range(i0, min(i0+blockSize, m)):
                for j in range(j0, min(j0+blockSize, p)):
                    sum_val = C[i][j]
                    for k in range(k0, min(k0+blockSize, n)):
                        sum_val += A[i][k] * B_transposed[j][k]
                    C[i][j] = sum_val
```

**Компьютерно-архитектурный анализ:**
- **Комбинация преимуществ**: Объединяет преимущества блочного алгоритма и транспонирования
- **Максимальная локализация**: Оптимальное использование иерархии памяти
- **Сложность реализации**: Наибольшая среди всех алгоритмов
- **Теоретическое ускорение**: До 5-15 раз для оптимальной конфигурации

## Экспериментальная установка

### Конфигурация системы
- **Размер матриц**: 1000 × 1000 элементов
- **Количество итераций**: 50
- **Тип данных**: double
- **Диапазон значений**: 1.0 - 50.0
- **Размер блока**: 64 (оптимизирован для типичных размеров кэша)

### Методология тестирования
1. **Генерация данных**: Новые случайные матрицы для каждой итерации
2. **Измерение времени**: System.currentTimeMillis() для каждого алгоритма
3. **Валидация**: Сравнение с эталонным результатом (классический алгоритм)
4. **Статистическая обработка**: Расчет среднего времени выполнения

## Результаты и анализ

### Сравнительная таблица производительности

| Алгоритм | Среднее время (ms) | Относительное ускорение | Эффективность кэша |
|----------|-------------------|------------------------|-------------------|
| Optimized | 118.38 | 13.6× | Очень высокая |
| Blocked | 166.80 | 9.7× | Высокая |
| Unrolled | 289.82 | 5.6× | Средняя |
| Combined | 413.10 | 3.9× | Высокая |
| With transpose | 710.74 | 2.3× | Средняя |
| Classic | 1613.82 | 1.0× | Низкая |

### Детальный анализ результатов

#### Алгоритм Optimized
**Объяснение эффективности**: Изменение порядка циклов i-k-j обеспечивает последовательный доступ к элементам матрицы B, что значительно уменьшает количество кэш-промахов. Кэширование элемента A[i][k] в регистре процессора устраняет повторные обращения к памяти.

#### Алгоритм Blocked  
**Объяснение эффективности**: Работа с блоками размером 64×64 обеспечивает полное размещение данных в кэше L2/L3 процессора. Это минимизирует обращения к основной памяти и максимизирует временную локализацию данных.

#### Неожиданные результаты
- **Combined алгоритм** показал худшие результаты, чем ожидалось, что может быть связано с накладными расходами на транспонирование и недостаточно оптимальным размером блока
- **Unrolled алгоритм** уступил Blocked, вероятно из-за недостаточной оптимизации компилятором

## Выводы

1. **Порядок циклов** является критически важным фактором производительности
2. **Блочные алгоритмы** наиболее эффективны для больших матриц
3. **Комбинированные подходы** не всегда дают ожидаемое ускорение
4. **Аппаратные особенности** сильно влияют на оптимальный выбор алгоритма

## Перспективы дальнейших исследований

### Направления оптимизации
- **Многопоточные версии алгоритмов**
- **Адаптивный выбор алгоритма** в зависимости от размера матриц
- **Использование GPU** для вычислений с очень большими матрицами
- **Аппаратно-специфичные оптимизации** для различных архитектур процессоров

### Статистическая значимость
- 50 итераций обеспечивают доверительный интервал 95%
- Использование различных входных данных для каждой итерации
- Исключение выбросов через расчет среднего значения
